import os
import time
import asyncio
import random
import operator
from typing import TypedDict, Annotated, List, Any, Dict

#naver api
from naver_api import build_snippet_per_doc, format_snippets_as_text

# OpenAI SDK
from openai import AsyncOpenAI

# LangChain / Vector store
from langgraph.graph import StateGraph, END
from langchain_core.documents import Document
from dotenv import load_dotenv
import numpy as np
from neo4j import AsyncGraphDatabase

# BGE-M3 í†µí•© ì‚¬ìš©
from FlagEmbedding import BGEM3FlagModel
import json

load_dotenv()

  
#Neo4j ë“œë¼ì´ë²„ (í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸° ê¶Œì¥)
uri = os.getenv("NEO4J_URI")
driver = AsyncGraphDatabase.driver(uri, auth=(os.getenv("NEO4J_USER"), os.getenv("NEO4J_PASSWORD")))



# --- ê°€ì¤‘ì¹˜ & íŒŒë¼ë¯¸í„° ì„¤ì • ---
TOPK_CAMP = 100       # Campì—ì„œ ì´ˆê¸° í›„ë³´ ìˆ˜
TOPK_ATTR = 100        # Attributeì—ì„œ ì´ˆê¸° í›„ë³´ ìˆ˜
TOPK_SUM = 100       # Summaryì—ì„œ ì´ˆê¸° í›„ë³´ ìˆ˜
ROLLUP_LIMIT = 2     # Camp ì§‘ê³„ í›„ ìƒìœ„ ëª‡ ê°œë¡œ ì¤„ì¼ì§€
FINAL_TOPN = 2        # ìµœì¢… ì¶”ì²œ ê°œìˆ˜
WEIGHT_CAMP = 3.0
WEIGHT_ATTR = 0.3
WEIGHT_SUM = 0.3

VECTOR_DIM = 1024     # BGE-M3 Dense ì°¨ì›
SIM_FUNC = "cosine"   # 'cosine' ì¶”ì²œ


# ===== í™˜ê²½ ì„¤ì • =====
# âš ï¸ í‚¤ëŠ” í™˜ê²½ë³€ìˆ˜ë¡œ ì½ìŠµë‹ˆë‹¤: export OPENAI_API_KEY="sk-..."
client = AsyncOpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    timeout=30.0,
)

EMBEDDING_MODEL_NAME = "dragonkue/BGE-m3-ko"
MAX_LOOPS = 2

GPT_MODEL = "ft:gpt-4.1-mini-2025-04-14:ailab:camping-rag-qa:C2bHhwJM:ckpt-step-714"

class UnifiedBGEM3Embedder:
    def __init__(self, model_name="dragonkue/BGE-m3-ko"):
        self.model = None
        self.model_name = model_name
        self._load_model()
    
    def _load_model(self):
        """BGE-M3 ëª¨ë¸ ë¡œë“œ"""
        try:
            self.model = BGEM3FlagModel(self.model_name, use_fp16=True)
            print(f"âœ… BGE-M3 í†µí•© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {self.model_name}")
        except Exception as e:
            print(f"âŒ BGE-M3 í•œêµ­ì–´ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            try:
                # Fallback: ì›ë³¸ BGE-M3 ëª¨ë¸
                self.model = BGEM3FlagModel('BAAI/bge-m3', use_fp16=True)
                print("âœ… BGE-M3 ì›ë³¸ ëª¨ë¸ë¡œ Fallback ë¡œë“œ ì™„ë£Œ")
            except Exception as e2:
                print(f"âŒ BGE-M3 Fallbackë„ ì‹¤íŒ¨: {e2}")
                self.model = None

    # --- ì´ ë¶€ë¶„ì„ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤ ---
    def encode_for_vector_db(self, texts: List[str]):
        """Neo4jìš© dense embedding ìƒì„±"""
        if self.model is None:
            raise Exception("BGE-M3 ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # BGE-M3 ëª¨ë¸ì˜ encode ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ dense ë²¡í„°ë¥¼ ìƒì„±
        embeddings = self.model.encode(
            texts,
            batch_size=32,
            return_dense=True,
            return_sparse=False,
            return_colbert_vecs=False
        )
        
        return embeddings['dense_vecs']
  

# âœ… í†µí•© ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
unified_embedder = UnifiedBGEM3Embedder(EMBEDDING_MODEL_NAME)

# ===== ìƒíƒœ ì •ì˜ =====
class GraphState(TypedDict):
    question: str
    original_question: str
    classification: str
    camping_type_preference: str
    context: Annotated[List[Any], operator.add]
    locations: Annotated[List[dict], operator.add]
    final_answer: str
    loop_count: int
    search_attempted: bool
    error_message: str

#===== ê³µìš© LLM í˜¸ì¶œ ìœ í‹¸ =====

async def oai_text(prompt: str, model: str = GPT_MODEL) -> Dict[str, Any]:
    """Responses APIë¡œ í…ìŠ¤íŠ¸ë§Œ ë°›ì•„ì˜¤ëŠ” í—¬í¼.
    ë°˜í™˜: {"text": str, "request_id": str}
    """
    resp = await client.responses.create(
        model=model,
        input=prompt,
    )
    # ê³µì‹ SDKëŠ” output_text ì œê³µ â†’ íŒŒì‹± ì¸ë±ìŠ¤ ì‹¤ìˆ˜ ë°©ì§€
    return {"text": (resp.output_text or "").strip(), "request_id": getattr(resp, "_request_id", None)}

# --- 1ì°¨ ë¶„ë¥˜ ë…¸ë“œ ---

async def classify_question_type(state: GraphState) -> dict:
    t0 = time.perf_counter()
    question = state["question"]
    prompt = (
        "ë‹¹ì‹ ì€ ìº í•‘ì— ëŒ€í•œ ì§ˆë¬¸ì„ í•˜ëŠ”ì§€ ë†€ëŸ¬ê°ˆ ì¥ì†Œë¥¼ ì¶”ì²œí•´ë‹¬ë¼ê³  í•˜ëŠ” ì§ˆë¬¸ì„ í•˜ëŠ”ì§€ ë¶„ë¥˜í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n"
        "ë‹¤ìŒ ì§ˆë¬¸ì„ ì½ê³  ì¼ë°˜ ìº í•‘ì— ê´€í•œ ì§ˆë¬¸ì´ë©´ 'ì¼ë°˜ ìº í•‘' ìœ¼ë¡œ ë‹µí•˜ê³ , ë†€ëŸ¬ê°€ëŠ” ì¥ì†Œì— ê´€í•œ ì§ˆë¬¸ì´ë‚˜ ë¬¸ë§¥ìƒ ì¥ì†Œë¥¼ ì¶”ì²œí•´ì•¼í•˜ëŠ” ì§ˆë¬¸ì€ 'ì¥ì†Œ ì¶”ì²œ'ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”.\n" 
        "'ì¼ë°˜ ìº í•‘', 'ì¥ì†Œ ì¶”ì²œ' ë‘˜ ì¤‘ í•˜ë‚˜ë¡œ ë‹µë³€í•˜ì„¸ìš”.\n\n"
        f"ì§ˆë¬¸: {question}\n"
        "ë¶„ë¥˜:"
    )
    try:
        out = await oai_text(prompt)
        text = out["text"]

        categories = ["ì¼ë°˜ ìº í•‘", "ì¥ì†Œ ì¶”ì²œ"]

        # ë¬¸ì¥ ì „ì²´ì—ì„œ ì¹´í…Œê³ ë¦¬ ë‹¨ì–´ê°€ ìˆëŠ”ì§€ í™•ì¸
        classification = next((cat for cat in categories if cat in text), "ì¼ë°˜ ìº í•‘")

        print(f"ë¶„ë¥˜: {classification} ({time.perf_counter() - t0:.2f}s)")
        return {"classification": classification, "original_question": question}

    except Exception as e:
        print(f"ë¶„ë¥˜ ì˜¤ë¥˜: {e} ({time.perf_counter() - t0:.2f}s)")
        return {"classification": "ì¼ë°˜ ìº í•‘", "original_question": question, "error_message": str(e)}
        
# --- ì¼ë°˜ ì§ˆë¬¸ ë‹µë³€ ë…¸ë“œ ---

async def generate_general_answer(state: GraphState) -> dict:
    t0 = time.perf_counter()
    question = state["question"]
    prompt = (
        "ë‹¹ì‹ ì€ ìº í•‘ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ìº í•‘ ê´€ë ¨ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n\n"
        f"ì§ˆë¬¸: {question}\n"
        "ì¤„ ë°”ê¿ˆì„ ì´ìš©í•˜ì—¬ ê°€ë…ì„± ì¢‹ê²Œ ë‹µë³€ í•´ ì£¼ì„¸ìš”."
        "ë‹µë³€:"
    )
    try:
        out = await oai_text(prompt)
        answer = out["text"]
        print(f"ì¼ë°˜ì§ˆë¬¸ ì‘ë‹µ ({time.perf_counter() - t0:.2f}s | req={out['request_id']})")
        return {"final_answer": answer}
    except Exception as e:
        print(f"ì¼ë°˜ì§ˆë¬¸ ì˜¤ë¥˜: {e} ({time.perf_counter() - t0:.2f}s)")
        return {"final_answer": "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", "error_message": str(e)}

# --- ë¼ìš°íŒ… í•¨ìˆ˜ ---

def route_by_classification(state):
    return "general" if state.get("classification") == "ì¼ë°˜ ìº í•‘" else "ask_preference"

def route_by_camping_type(state):
    mapping = {
        "ìœ ë£Œìº í•‘ì¥": "paid",
        "ê¸€ë¨í•‘/ì¹´ë¼ë°˜": "glamping",
        "ì˜¤ì§€/ë…¸ì§€ìº í•‘": "ojee",
    }
    return mapping.get(state.get("camping_type_preference", "ìœ ë£Œìº í•‘ì¥"), "paid")

# --- ìº í•‘ ìœ í˜• ì„ íƒ ìš”ì²­ ë…¸ë“œ ---

async def ask_camping_preference(state: GraphState) -> dict:
    message = (
        "ğŸ•ï¸ ì¥ì†Œë¥¼ ì¶”ì²œí•´ë“œë¦´ê²Œìš”! ì–´ë–¤ ìŠ¤íƒ€ì¼ì˜ ìº í•‘ì„ ì›í•˜ì‹œë‚˜ìš”?\n\n"
        "â–¶ ìœ ë£Œìº í•‘ì¥ (ì˜¤í† ìº í•‘ì¥, í¸ì˜ì‹œì„¤ ì™„ë¹„)  \n"
        "â–¶ ê¸€ë¨í•‘/ì¹´ë¼ë°˜ (ëŸ­ì…”ë¦¬, í¸ì•ˆí•œ ìº í•‘)  \n"
        "â–¶ ì˜¤ì§€/ë…¸ì§€ìº í•‘ (ìì—° ì† ë¬´ë£Œ ìº í•‘)  \n\n"
        "ì¸ì›ì´ë‚˜ ìŠ¤íƒ€ì¼ ë“± ëª¨ë‘ ì•Œë ¤ì£¼ì„¸ìš”!"
    )
    return {"final_answer": message}

# --- ìº í•‘ ìœ í˜• ë¶„ë¥˜ ë…¸ë“œ ---
async def classify_camping_type(state: GraphState) -> dict:
    t0 = time.perf_counter()
    user_input = state["question"]  # ì‚¬ìš©ìì˜ ë‹µë³€
    original_question = state.get("original_question", "")
    
    prompt = (
        "ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ìº í•‘ ìœ í˜• ì„ í˜¸ë„ë¥¼ ë¶„ë¥˜í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n"
        "ì‚¬ìš©ìì˜ ì‘ë‹µê³¼ ì›ë˜ ì§ˆë¬¸ì„ ì½ê³  'ìœ ë£Œìº í•‘ì¥', 'ê¸€ë¨í•‘/ì¹´ë¼ë°˜', 'ì˜¤ì§€/ë…¸ì§€ìº í•‘' ì¤‘ í•˜ë‚˜ë¡œ ì •í™•í•˜ê²Œ ì¹´í…Œê³ ë¦¬ë§Œì„ ë‹µë³€í•˜ì„¸ìš”.\n\n"
        f"ì›ë˜ ì§ˆë¬¸: {original_question}\n"
        f"ì‚¬ìš©ì ì‘ë‹µ: {user_input}\n"
        "ë¶„ë¥˜:"
    )
    
    try:
        out = await oai_text(prompt)
        text = out["text"]

        categories = ["ìœ ë£Œìº í•‘ì¥", "ê¸€ë¨í•‘/ì¹´ë¼ë°˜", "ì˜¤ì§€/ë…¸ì§€ìº í•‘"]
        camping_type = next((cat for cat in categories if cat in text), "ìœ ë£Œìº í•‘ì¥")

        print(f"ìº í•‘ìœ í˜•: {camping_type} ({time.perf_counter() - t0:.2f}s)")
        return {"camping_type_preference": camping_type}

    except Exception as e:
        print(f"ìº í•‘ìœ í˜• ë¶„ë¥˜ ì˜¤ë¥˜: {e} ({time.perf_counter() - t0:.2f}s)")
        return {"camping_type_preference": "ìœ ë£Œìº í•‘ì¥", "error_message": str(e)}



async def ensure_vector_indexes(session):
    """Camp/Attribute/Summary ë²¡í„° ì¸ë±ìŠ¤ë¥¼ ë³´ì¥ (ì´ë¯¸ ìˆìœ¼ë©´ ë¬´ì‹œ)."""
    # Neo4j 5.x: IF NOT EXISTS ì§€ì›. ë¯¸ì§€ì› ë²„ì „ì´ë©´ try/exceptë¡œ ë¬´ì‹œ.
    stmts = [
        f"""
        CREATE VECTOR INDEX camp_embedding_index IF NOT EXISTS
        FOR (c:Camp) ON (c.embedding)
        OPTIONS {{
          indexConfig: {{
            `vector.dimensions`: {VECTOR_DIM},
            `vector.similarity_function`: '{SIM_FUNC}'
          }}
        }};
        """,
         f"""
        CREATE VECTOR INDEX attr_embedding_index IF NOT EXISTS
        FOR (a:Attribute) ON (a.embedding)
        OPTIONS {{
          indexConfig: {{
            `vector.dimensions`: {VECTOR_DIM},
            `vector.similarity_function`: '{SIM_FUNC}'
          }}
        }};
        """,
         f"""
        CREATE VECTOR INDEX summary_embedding_index IF NOT EXISTS
        FOR (s:Summary) ON (s.embedding)
        OPTIONS {{
          indexConfig: {{
            `vector.dimensions`: {VECTOR_DIM},
            `vector.similarity_function`: '{SIM_FUNC}'
          }}
        }};
        """
    ]
    for stmt in stmts:
        try:
            await session.run(stmt)
        except Exception as _:
            # ì´ë¯¸ ì¡´ì¬í•˜ê±°ë‚˜ ë²„ì „ ì´ìŠˆë©´ ì¡°ìš©íˆ í†µê³¼
            pass
def _rollup_query():
    """
    Camp/Attribute/Summary ê°ê°ì˜ ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ë¥¼ Campë¡œ ì˜¬ë ¤ ì§‘ê³„í•˜ëŠ” Cypher.
    - camp.type = $camping_type í•„í„°
    - scoreëŠ” ì†ŒìŠ¤ë³„ ê°€ì¤‘ì¹˜ë¥¼ ê³±í•´ í•©ì‚°
    - ìƒìœ„ $rollup_limitê¹Œì§€ ë°˜í™˜
    """
    return """
    // 1) Sourceë³„ ë²¡í„° ê²€ìƒ‰
    CALL {
      // Camp ì§ì ‘ ê²€ìƒ‰
      CALL db.index.vector.queryNodes('camp_embedding_index', $topk_camp, $q) YIELD node, score
      WITH node AS camp, score * $w_camp AS s, 'camp' AS src
      WHERE camp.type = $camping_type
      RETURN camp, s, src
      UNION
      // Attributeì—ì„œ ê²€ìƒ‰ í›„ ë¶€ëª¨ Campë¡œ ìŠ¹ê²©
      CALL db.index.vector.queryNodes('attr_embedding_index', $topk_attr, $q) YIELD node, score
      MATCH (camp:Camp)-[:HAS_ATTRIBUTE]->(node)
      WITH DISTINCT camp, score * $w_attr AS s, 'attr' AS src
      WHERE camp.type = $camping_type
      RETURN camp, s, src
      UNION
      // Summaryì—ì„œ ê²€ìƒ‰ í›„ ë¶€ëª¨ Campë¡œ ìŠ¹ê²©
      CALL db.index.vector.queryNodes('summary_embedding_index', $topk_sum, $q) YIELD node, score
      MATCH (camp:Camp)-[:HAS_SUMMARY]->(node)
      WITH DISTINCT camp, score * $w_sum AS s, 'summary' AS src
      WHERE camp.type = $camping_type
      RETURN camp, s, src
    } 

    // 2) Camp ë‹¨ìœ„ë¡œ ì ìˆ˜ ì§‘ê³„ (WHERE í•„í„°ëŠ” ê° UNION ë‚´ë¶€ë¡œ ì´ë™í–ˆìœ¼ë¯€ë¡œ ì œê±°)
    WITH camp, collect({src:src, score:s}) AS parts, reduce(total=0.0, x IN collect(s) | total + x) AS totalScore
    ORDER BY totalScore DESC
    LIMIT $rollup_limit

    // 3) ê´€ë ¨ Attribute / Summary ê¸ì–´ì˜¤ê¸°
    OPTIONAL MATCH (camp)-[ra:HAS_ATTRIBUTE]->(a:Attribute)
    WITH camp, parts, totalScore, collect({type: ra.type, text: a.text}) AS attributes
    OPTIONAL MATCH (camp)-[:HAS_SUMMARY]->(s:Summary)
    WITH camp, parts, totalScore, attributes, collect(s.text) AS summaries

    RETURN camp, parts, totalScore, attributes, summaries
    ORDER BY totalScore DESC
    """

def _camp_to_location_dict(record):
    """Cypher ë°˜í™˜ ë ˆì½”ë“œë¥¼ locations[] ìš”ì†Œë¡œ ë³€í™˜."""
    camp_node = record["camp"]
    # attributes = record.get("attributes", []) or []  # ì‚­ì œ
    # summaries = record.get("summaries", []) or []  # ì‚­ì œ
    score = float(record.get("totalScore", 0.0))
    parts = record.get("parts", []) or []

    # === ë¡œê¹… ì¶”ê°€ ===
    camp_name = camp_node.get("name", "Unknown")
    print(f"ìº í•‘ì¥: {camp_name}")
    print(f" Â ì´ì : {score:.4f}")

    # parts ì „ì²´ êµ¬ì¡° í™•ì¸
    print(f" Â parts ê°œìˆ˜: {len(parts)}")
    for i, part in enumerate(parts):
        src = part.get("src", "unknown")
        part_score = part.get("score", 0.0)
        print(f" Â - [{i}] {src}: {part_score:.4f}")

    # camp ì†ŒìŠ¤ê°€ ì—†ëŠ”ì§€ ëª…ì‹œì  ì²´í¬
    camp_sources = [p for p in parts if p.get("src") == "camp"]
    if not camp_sources:
        print(f" Â âš ï¸ Â ì´ ìº í•‘ì¥ì€ camp ì§ì ‘ ê²€ìƒ‰ì—ì„œëŠ” ë°œê²¬ë˜ì§€ ì•ŠìŒ")
    print()  # êµ¬ë¶„ìš© ë¹ˆ ì¤„

    # camp_nodeëŠ” Node ê°ì²´. í”„ë¡œí¼í‹° êº¼ë‚´ê¸°
    camp_props = dict(camp_node)

    # metaê°€ JSON ë¬¸ìì—´ë¡œ ì €ì¥ë˜ì–´ ìˆë‹¤ë©´ ê·¸ëŒ€ë¡œ contentë¡œ ì‚¬ìš©
    raw_meta = camp_props.get("meta")
    content_str = ""
    if isinstance(raw_meta, str) and raw_meta:
        content_str = raw_meta
    else:
        # ì•ˆì „ë§: í•µì‹¬ í”„ë¡œí¼í‹° í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±
        content_str = json.dumps({
            "ìº í•‘ì¥ì´ë¦„": camp_props.get("name"),
            "ìš´ì˜ìƒíƒœ": camp_props.get("status"),
            "ìº í•‘ì¥ì£¼ì†Œ": camp_props.get("address"),
            "ìº í•‘ìœ í˜•": camp_props.get("type"),
            "ìº í•‘ì¥ì‹œì„¤": camp_props.get("facilities"),
            "ì¦ê¸¸ê±°ë¦¬": camp_props.get("activities")
        }, ensure_ascii=False)

    # ë¬¸ë§¥ ê°•í™”ìš©: Attribute / Summary ì‚­ì œ
    # attr_texts = [f"[{a.get('type','')}] {a.get('text','')}" for a in attributes if a.get("text")]
    # sum_texts = [s for s in summaries if s]

    # combined_contextì—ì„œ attrê³¼ summary ê´€ë ¨ ë‚´ìš© ëª¨ë‘ ì œê±°
    combined_context = "\n".join([
        "## CAMP META",
        content_str,
        # "## ATTRIBUTES",
        # "\n".join(attr_texts[:20]),
        # "## SUMMARIES",
        # "\n".join(sum_texts[:20]),
    ])

    camp_meta = json.loads(camp_props.get("meta"))
    
    lat = camp_meta["ìº í•‘ì¥ ìœ„ë„"] # ìœ„ë„
    lon = camp_meta["ìº í•‘ì¥ ê²½ë„"]

    # LangChain Documentë¡œ ê°ì‹¸ ë„¤ì´ë²„ í•¨ìˆ˜ì™€ í˜¸í™˜
    # ë©”íƒ€ë°ì´í„° í‚¤ëŠ” ê¸°ì¡´ Chroma ë²„ì „ê³¼ ë™ì¼í•˜ê²Œ ë§ì¶°ì¤Œ
    meta_for_doc = {
        "ìº í•‘ì¥ì´ë¦„": camp_props.get("name", ""),
        "ìš´ì˜ìƒíƒœ": camp_props.get("status"),
        "ìº í•‘ì¥ì£¼ì†Œ": camp_props.get("address"),
        "ìº í•‘ìœ í˜•": camp_props.get("type"),
        "ìº í•‘ì¥ì‹œì„¤": camp_props.get("facilities"),
        "ì¦ê¸¸ê±°ë¦¬": camp_props.get("activities"),
        "ìº í•‘ì¥ ìœ„ë„": lat,
        "ìº í•‘ì¥ ê²½ë„": lon
    }
    doc = Document(page_content=combined_context, metadata=meta_for_doc)

    # locations[] í‘œì¤€ í˜•íƒœ
    location_info = {
        "local_document": {
            "metadata": meta_for_doc,
            "content": combined_context,
            "score": score
        },
        "doc_for_web": doc,     # ë„¤ì´ë²„ ìŠ¤ë‹ˆí« í•¨ìˆ˜ì— ë„˜ê¸°ê¸° ìœ„í•œ ì›ë³¸
        "web_snippet": None     # ë‚˜ì¤‘ì— ì¡°ê±´ë¶€ë¡œ ì±„ì›€
    }
    return location_info


async def search_camping(state: dict, camping_type: str) -> dict:
    """
    Neo4j ê¸°ë°˜ GraphRAG ê²€ìƒ‰:
    - Camp/Attribute/Summaryì—ì„œ ê°ê° ë²¡í„° ê²€ìƒ‰ â†’ Campë¡œ ìŠ¹ê²©/ì§‘ê³„
    - Campì˜ ì—°ê²°(Attributes, Summaries)ê¹Œì§€ ëª¨ë‘ ì‹¤ì–´ ë¬¸ë§¥ êµ¬ì„±
    - camping_typeì´ 'ì˜¤ì§€/ë…¸ì§€ìº í•‘'ì´ë©´ RAGë§Œ ì‚¬ìš©, ê·¸ ì™¸ ìœ í˜•ì´ë©´ ì›¹ ìŠ¤ë‹ˆí« ë³‘í•©
    """
    search_query = (
    f"ì‚¬ìš©ì ì›ë˜ ì§ˆë¬¸: {state.get('original_question', '')}\n"
    f"ì‚¬ìš©ì ìº í•‘ ìœ í˜• ë‹µë³€: {state.get('question', '')}").strip()
    print(search_query)
    print(f"\n--- ğŸ” Neo4j GraphRAG (í•„í„°: {camping_type}) ---")

    try:
        # 0) ì¿¼ë¦¬ ì„ë² ë”©
        dense_vecs = await asyncio.to_thread(unified_embedder.encode_for_vector_db, [search_query])
        query_vec = dense_vecs[0].tolist()

        async with driver.session() as session:
            await ensure_vector_indexes(session)  # ì¸ë±ìŠ¤ ë³´ì¥

            # 1) Roll-up ê²€ìƒ‰ ì‹¤í–‰
            records = await session.run(
                _rollup_query(),
                q=query_vec,
                camping_type=camping_type,
                topk_camp=TOPK_CAMP,
                topk_attr=TOPK_ATTR,
                topk_sum=TOPK_SUM,
                w_camp=WEIGHT_CAMP,
                w_attr=WEIGHT_ATTR,
                w_sum=WEIGHT_SUM,
                rollup_limit=ROLLUP_LIMIT,
            )
            # ê²°ê³¼ë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ ê°€ì ¸ì˜´
            rows = [record async for record in records]

        if not rows:
            print("ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
            return {"locations": []}

        print(f"ğŸ“„ Neo4jì—ì„œ Camp í›„ë³´ {len(rows)}ê°œ ì§‘ê³„ë¨")

        # 2) Python ì¸¡ì—ì„œ ìµœì¢… TOP N ê³ ë¥´ê³  locations êµ¬ì¡° ë§Œë“¤ê¸°
        locations = []
        for rec in rows[:FINAL_TOPN]:
            locations.append(_camp_to_location_dict(rec))

        # 3) ìº í•‘ìœ í˜•ì— ë”°ë¼ ì›¹ ìŠ¤ë‹ˆí« í˜¸ì¶œ ì—¬ë¶€ ê²°ì •
        if camping_type != "ì˜¤ì§€/ë…¸ì§€ìº í•‘" and locations:
            # ìœ ë£Œ/ê¸€ë¨í•‘ì¼ ë•Œë§Œ ë„¤ì´ë²„ API í˜¸ì¶œ
            docs_with_metadata = []
            for loc in locations:
                doc = loc["doc_for_web"]
                score = float(loc["local_document"]["score"])
                docs_with_metadata.append((doc, score))

            try:
                snippets = await build_snippet_per_doc(
                    docs_with_metadata=docs_with_metadata,
                    per_type_display=20,
                    fetch_timeout=8,
                    max_chars=2000,
                    enforce_name_in_title=True,
                    include_when_no_local_modified=True,
                )
                snippet_map = {s["ì¥ì†Œì´ë¦„"]: s for s in snippets}
                for loc in locations:
                    place_name = loc["local_document"]["metadata"].get("ìº í•‘ì¥ì´ë¦„", "")
                    if place_name in snippet_map:
                        loc["web_snippet"] = snippet_map[place_name]
            except Exception as e:
                print(f"[ì›¹ ìŠ¤ë‹ˆí« ì˜¤ë¥˜] {e}")

        # 4) ë‚´ë¶€ìš© í‚¤ ì œê±°
        for loc in locations:
            loc.pop("doc_for_web", None)

        return {"locations": locations}

    except Exception as e:
        print(f"âŒ Neo4j GraphRAG ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return {"locations": []}


# --- ë˜í¼: ìœ í˜•ë³„ ê²€ìƒ‰ ---
async def search_paid_camping(state):
    return await search_camping(state, "ìœ ë£Œìº í•‘ì¥")

async def search_glamping_caravan(state):
    return await search_camping(state, "ê¸€ë¨í•‘/ì¹´ë¼ë°˜")

async def search_ojee_camping(state):
    return await search_camping(state, "ì˜¤ì§€/ë…¸ì§€ìº í•‘")


# --- ì¥ì†Œ ì¶”ì²œ ìµœì¢… ë‹µë³€ ìƒì„± ---
async def generate_location_answer(state: GraphState) -> dict:
    t0 = time.perf_counter()    
    original_question = state.get("original_question", "")
    second_question = state.get("question", "")
    camping_type = state.get("camping_type_preference", "")
    context = state.get("context", [])
    locations = state.get("locations", [])
    print(f"[DEBUG] ìµœì¢… ë°˜í™˜ë  ì¥ì†Œ ê°œìˆ˜: {len(locations)}ê°œ")
    
    context_strs = []
    final_locations = []
    for loc in locations:
        local_meta = loc.get("local_document", {}).get("metadata", {})
        local_content = loc.get("local_document", {}).get("content", "")
        snippet = loc.get("web_snippet", {})
        snippet_text = snippet.get("snippet", "") if snippet else ""
        
        
        # ì˜¬ë°”ë¥¸ ë©”íƒ€ë°ì´í„° ì ‘ê·¼ ë° final_locations ìƒì„±
        location_data = {
            "name": local_meta.get('ìº í•‘ì¥ì´ë¦„'),
            "address": local_meta.get('ìº í•‘ì¥ì£¼ì†Œ'),
            "latitude": local_meta.get('ìº í•‘ì¥ ìœ„ë„'),
            "longitude": local_meta.get('ìº í•‘ì¥ ê²½ë„'),
            "local_meta": local_meta,
        }
        final_locations.append(location_data)
        
        context_strs.append(
            f"ë©”íƒ€ë°ì´í„°: {final_locations}"
            f"ë³¸ë¬¸: {local_content}"
            f"ë„¤ì´ë²„ ì •ë³´: {snippet_text}"
        )

    context_str = "\n---".join(context_strs[:2])  # ìµœëŒ€ 2ê°œê¹Œì§€ë§Œ

    prompt = (
        f"ë‹¹ì‹ ì€ ìº í•‘ì—ì´ì „íŠ¸ ì±—ë´‡ì…ë‹ˆë‹¤. ì•„ë˜ ë¬¸ë§¥ì„ ì°¸ê³ í•˜ì—¬ '{camping_type}' ìœ í˜•ì— ë§ëŠ” ì¥ì†Œë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”. ìµœëŒ€í•œ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”.\n"
        "ì¶”ì²œ ì‹œì—ëŠ” ë°˜ë“œì‹œ ë¬¸ë§¥ ë‚´ ë©”íƒ€ë°ì´í„°ì™€ ìµœì‹  ë„¤ì´ë²„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.\n"
        "ì‚¬ì´íŠ¸ë‚˜ ì „í™”ë²ˆí˜¸ë¥¼ ë§í•´ì¤„ë•ŒëŠ” \"ëª¨ë“  ì •ë³´ëŠ” ìµœì‹ ì´ ì•„ë‹ ìˆ˜ ìˆìœ¼ë‹ˆ ê³µì‹ ì‚¬ì´íŠ¸/ì „í™”ë¡œ ì¬í™•ì¸ ë°”ëë‹ˆë‹¤.\"ë¼ê³  ë§ë¶™ì—¬ì£¼ì„¸ìš”.\n\n"
        
        f"ì²« ë²ˆì§¸ ì§ˆë¬¸: {original_question}\n"
        f"ë‘ ë²ˆì§¸ ì§ˆë¬¸ ë° ì‚¬ìš©ìì˜ ìº í•‘ ìœ í˜• ë‹µë³€: {second_question}\n\n"
        
        f"ë¬¸ë§¥:\n{context_str}\n\n"
        
        "ìœ„ ë‚´ìš©ì„ ê³ ë ¤í•˜ì—¬ ì¤„ë°”ê¿ˆì„ ì´ìš©í•˜ì—¬ ê°€ë…ì„± ì¢‹ê²Œ ë‹µë³€ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.\n"
        "ë‹µë³€:"
    )
    try:
        out = await oai_text(prompt)
        answer = out["text"]
        print(f"âœ… ì¥ì†Œ ì¶”ì²œ ë‹µë³€ ìƒì„± ì™„ë£Œ ({time.perf_counter() - t0:.2f}s | req={out['request_id']})")
        return {"final_answer": answer, "locations": final_locations}
    except Exception as e:
        print(f"âŒ ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {e} ({time.perf_counter() - t0:.2f}s)")
        return {"final_answer": "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", "error_message": str(e), "locations": final_locations}

# --- ë©”ì¸ ì›Œí¬í”Œë¡œìš° ---
workflow = StateGraph(GraphState)
workflow.add_node("classify_type", classify_question_type)
workflow.add_node("generate_general", generate_general_answer)
workflow.add_node("ask_preference", ask_camping_preference)
workflow.set_entry_point("classify_type")
workflow.add_conditional_edges(
    "classify_type",
    route_by_classification,
    {
        "general": "generate_general",
        "ask_preference": "ask_preference",
    },
)
workflow.add_edge("generate_general", END)
workflow.add_edge("ask_preference", END)

# --- ìº í•‘ ìœ í˜• í›„ì† ì›Œí¬í”Œë¡œìš° ---
continuation = StateGraph(GraphState)
continuation.add_node("classify_camping", classify_camping_type)
continuation.add_node("search_paid", search_paid_camping)
continuation.add_node("search_glamping", search_glamping_caravan)
continuation.add_node("search_ojee", search_ojee_camping)
continuation.add_node("generate_location", generate_location_answer)
continuation.set_entry_point("classify_camping")
continuation.add_conditional_edges(
    "classify_camping",
    route_by_camping_type,
    {
        "paid": "search_paid",
        "glamping": "search_glamping",
        "ojee": "search_ojee",
    },
)
continuation.add_edge("search_paid", "generate_location")
continuation.add_edge("search_glamping", "generate_location")
continuation.add_edge("search_ojee", "generate_location")
continuation.add_edge("generate_location", END)

main_app = workflow.compile()
continuation_app = continuation.compile()

# --- ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ ---

async def main():
    print("ğŸ•ï¸ ìº í•‘ ì±—ë´‡ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤! 'ì¢…ë£Œ'ë¥¼ ì…ë ¥í•˜ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.")
    waiting_for_camping_choice = False
    original_q_cache: str | None = None

    while True:
        user_input = await asyncio.to_thread(input, "\nâ“ ì‚¬ìš©ì ì§ˆë¬¸: ")
        user_input = user_input.strip()
        if user_input.lower() in ["ì¢…ë£Œ", "quit", "exit"]:
            print("ğŸ‘‹ ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        try:
            if waiting_for_camping_choice:
                # ìº í•‘ ìœ í˜• ì…ë ¥ ëŒ€ê¸° ì¤‘
                state: GraphState = {
                    "question": user_input,
                    "original_question": original_q_cache or user_input,
                    "context": [],
                    "search_attempted": False,
                    "loop_count": 0,
                }
                result = await continuation_app.ainvoke(state)
                waiting_for_camping_choice = False
                original_q_cache = None
            else:
                # ìƒˆë¡œìš´ ì§ˆë¬¸ ì²˜ë¦¬
                state: GraphState = {
                    "question": user_input,
                    "context": [],
                    "search_attempted": False,
                    "loop_count": 0,
                }
                result = await main_app.ainvoke(state)

                # ë‹¤ìŒ ì…ë ¥ìœ¼ë¡œ ìœ í˜•ì„ ë°›ë„ë¡ ì „í™˜
                if "ì–´ë–¤ ìŠ¤íƒ€ì¼ì˜ ìº í•‘ì„ ì›í•˜ì‹œë‚˜ìš”?" in result.get("final_answer", ""):
                    waiting_for_camping_choice = True
                    original_q_cache = state["question"]

            print(f"\nğŸ“ ë‹µë³€: {result.get('final_answer')}\n")

        except Exception as e:
            print(f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}")
            waiting_for_camping_choice = False
            original_q_cache = None

if __name__ == "__main__":
    asyncio.run(main())
